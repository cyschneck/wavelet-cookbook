{"version":"1","records":[{"hierarchy":{"lvl1":"Wavelet Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Wavelet Cookbook"},"content":"\n\n\n\n\n\n\n\n\n\nThis Project Pythia Cookbook covers how to work with wavelets in Python","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl2":"Motivation"},"content":"Wavelets are a powerful tool to analyze time-series data. When data frequencies vary over time, wavelets can be applied to analysis trends and overcome the time/frequency limitations of Fourier Transforms","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl2":"Authors"},"content":"Cora Schneck","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl2":"Structure"},"content":"This cookbook is broken into two main sections:\n\nIntroduction\n\nExample Geoscience Workflows","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl3":"Introduction","lvl2":"Structure"},"type":"lvl3","url":"/#introduction","position":10},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl3":"Introduction","lvl2":"Structure"},"content":"“Wavelet Basics”: Understand the motivation and background for wavelet analysis by reviewing time-series data and the strengths and weaknesses of other signal analysis tools like Fourier Transform\n\n“PyWavelets and Jingle Bells”: Learn how to use PyWavelets, a Python implementation of wavelet analysis, to determine the order of notes in a simple musical piece\n\n“Spy Keypad”: Learn how to use wavelets to undercover the frequency and order of notes in an unknown piece of audio data","type":"content","url":"/#introduction","position":11},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl3":"Geoscience Workflows","lvl2":"Structure"},"type":"lvl3","url":"/#geoscience-workflows","position":12},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl3":"Geoscience Workflows","lvl2":"Structure"},"content":"“Atmospheric Data: Nino 3 SST Index”: Learn how to apply wavelets to real atmospheric and oceanic data to generate a power wavelet scalogram, similar to the 1999 paper \n\n“A Practical Guide to Wavelet Analysis” by Torrence and Compo in Python","type":"content","url":"/#geoscience-workflows","position":13},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":14},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":15},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":16},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.","type":"content","url":"/#running-on-binder","position":17},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":18},{"hierarchy":{"lvl1":"Wavelet Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\nClone the https://github.com/ProjectPythia/wavelet-cookbook repository: git clone https://github.com/ProjectPythia/wavelet-cookbook.git\n\nMove into the wavelet-cookbook directorycd wavelet-cookbook\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate cookbook-dev\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":19},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index"},"type":"lvl1","url":"/nino3","position":0},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index"},"content":"\n\n","type":"content","url":"/nino3","position":1},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index"},"type":"lvl1","url":"/nino3#atmospheric-data-nino-3-sst-index","position":2},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index"},"content":"\n\n\n\n","type":"content","url":"/nino3#atmospheric-data-nino-3-sst-index","position":3},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Overview"},"type":"lvl2","url":"/nino3#overview","position":4},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Overview"},"content":"Generating a wavelet power and phase spectrum from the time-series data \n\nNino 3 SST Index\n\nPrerequisties\n\nBackground\n\nDownload and Organize Nino 3 SST Data\n\nWavelet Input Values\n\nPyWavelets\n\nPower Spectrum\n\nPhase Spectrum\n\n","type":"content","url":"/nino3#overview","position":5},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Prerequisites"},"type":"lvl2","url":"/nino3#prerequisites","position":6},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Matplotlib\n\nNecessary\n\nUsed to plot data\n\nIntro to Pandas\n\nNecessary\n\nUsed to read in and organize data (in particular dataframes)\n\nIntro to Numpy\n\nNecessary\n\nUsed to work with large arrays\n\nIntro to SciPy\n\nHelpful\n\nUsed to work with .wav files and built-in Fast Fourier Transform\n\nTime to learn: 45 minutes\n\n\n\n","type":"content","url":"/nino3#prerequisites","position":7},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Background"},"type":"lvl2","url":"/nino3#background","position":8},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Background"},"content":"","type":"content","url":"/nino3#background","position":9},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl3":"What is an El Niño?","lvl2":"Background"},"type":"lvl3","url":"/nino3#what-is-an-el-ni-o","position":10},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl3":"What is an El Niño?","lvl2":"Background"},"content":"Learn more!","type":"content","url":"/nino3#what-is-an-el-ni-o","position":11},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl3":"Wavelets and Atmospheric Data","lvl2":"Background"},"type":"lvl3","url":"/nino3#wavelets-and-atmospheric-data","position":12},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl3":"Wavelets and Atmospheric Data","lvl2":"Background"},"content":"Weather is a great example of time-series data. Weather varies in cycles of temperature over weeks due to a huge number of variables. Wavelet analysis can be used to find patterns in temperature by analyzing both the temperature and the time when the temperature occurs.\n\n","type":"content","url":"/nino3#wavelets-and-atmospheric-data","position":13},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Imports"},"type":"lvl2","url":"/nino3#imports","position":14},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Imports"},"content":"\n\nimport geocat.datafiles as gcd              # accessing nino3 data file\nimport xarray as xr                         # working with geocat-datafiles\n\nimport numpy as np                          # working with arrays\nimport pandas as pd                         # working with dataframes\nimport matplotlib.pyplot as plt             # plot data\n\nimport pywt                                 # PyWavelets\n\n","type":"content","url":"/nino3#imports","position":15},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Download Nino 3 SST Data"},"type":"lvl2","url":"/nino3#download-nino-3-sst-data","position":16},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Download Nino 3 SST Data"},"content":"\n\nWe will be downloading the sst_nino3 data from \n\ngeocat-datafiles\n\nnino3_data = gcd.get('ascii_files/sst_nino3.dat')\nnino3_data = np.loadtxt(nino3_data)\n\n","type":"content","url":"/nino3#download-nino-3-sst-data","position":17},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Plot and View Data"},"type":"lvl2","url":"/nino3#plot-and-view-data","position":18},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Plot and View Data"},"content":"Let’s give the data a look! We have over a hundred years worth of temperature readings.\n\nfig, ax = plt.subplots(figsize=(8, 8))\nplt.title(\"El Niño Sea Surface Temperature\")\nplt.xlabel(\"Years (from 1871)\")\nplt.ylabel(\"Sea Surface Temparture Changes\")\nplt.plot(nino3_data)\nplt.show()\n\n","type":"content","url":"/nino3#plot-and-view-data","position":19},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl3":"Update the X-Axis","lvl2":"Plot and View Data"},"type":"lvl3","url":"/nino3#update-the-x-axis","position":20},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl3":"Update the X-Axis","lvl2":"Plot and View Data"},"content":"By default, the loaded data lists the year as time since 1871, we can add a new x-axis to view the years along the x-axis\n\n# Convert default X-axis from time steps of 0-504 (0-len(nino3_data)) to Years\ndt = 0.25  # sampling period\nstart_year = 1871\nend_year = 1871 + (len(nino3_data) * dt)\nx_tickrange = np.arange(start_year, end_year, dt)\nstart = int(9 / dt)  # 36, starts the x-axis label at 1880 (9 years after start of data)\ndisplay_nth = int(20 / dt)  # 80, display x-axis label every 20 years\n\nfig, ax = plt.subplots(figsize=(8, 8))\nplt.title(\"El Niño Sea Surface Temperature\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Sea Surface Temparture Changes\")\nplt.xticks(range(len(x_tickrange))[start::display_nth], x_tickrange[start::display_nth]) # update x-axis\nplt.plot(nino3_data)\nplt.show()\n\n","type":"content","url":"/nino3#update-the-x-axis","position":21},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Wavelet Input Values"},"type":"lvl2","url":"/nino3#wavelet-input-values","position":22},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Wavelet Input Values"},"content":"\n\nWavelet inputs include:\n\nx: Input time-series data (for example, the time and temperature data from nino3)\n\nwavelet: mother wavelet name\n\ndt: sampling period (time between each y-value)\n\ns0: smallest scale\n\ndj: spacing between each discrete scales\n\njtot: largest scale\n\ndt = 0.25  # sampling period (time between each y-value)\ns0 = 0.25  # smallest scale\ndj = 0.25  # spacing between each discrete scales\njtot = 64  # largest scale\n\n","type":"content","url":"/nino3#wavelet-input-values","position":23},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl3":"Define Complex Morlet","lvl2":"Wavelet Input Values"},"type":"lvl3","url":"/nino3#define-complex-morlet","position":24},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl3":"Define Complex Morlet","lvl2":"Wavelet Input Values"},"content":"A complex Morlet allows us to define both the bandwidth and the center frequency that the Morlet wavelet will be built from to produce optimal results.\n\nHere you can learn more about how PyWavelets configures Complex Morlet wavelets\n\nBelow you can see how changing the bandwidth and center frequency will change how the mother Complex Morlet wavelet’s shape is formed. The shape of the wavelet will impact which frequencies it is sensitive to.\n\nwavelets = [f\"cmor{x:.1f}-{y:.1f}\" for x in [0.5, 1.5, 2.5] for y in [0.5, 1.0, 1.5]]\nfig, axs = plt.subplots(3, 3, figsize=(10, 10), sharex=True, sharey=True)\nfor ax, wavelet in zip(axs.flatten(), wavelets):\n    [psi, x] = pywt.ContinuousWavelet(wavelet).wavefun(10)\n    ax.plot(x, np.real(psi), label=\"real\")\n    ax.plot(x, np.imag(psi), label=\"imag\")\n    ax.set_title(wavelet)\n    ax.set_xlim([-5, 5])\n    ax.set_ylim([-0.8, 1])\nax.legend()\nplt.suptitle(\"Complex Morlet Wavelets with different center frequencies and bandwidths from PyWavelets\")\nplt.show()\n\nChanging the bandwidth and center frequency can be a useful tool to optimize how well the mother wavelet will be able to find frequencies in the data.\n\nBelow you will see how different values for bandwidth and center frequency can lead to greater or poorer resolution of the same signal.\n\n# Code below from: https://pywavelets.readthedocs.io/en/latest/ref/cwt.html\n\ndef gaussian(x, x0, sigma):\n    return np.exp(-np.power((x - x0) / sigma, 2.0) / 2.0)\n\n\ndef make_chirp(t, t0, a):\n    frequency = (a * (t + t0)) ** 2\n    chirp = np.sin(2 * np.pi * frequency * t)\n    return chirp, frequency\n\n\ndef plot_wavelet(time, data, wavelet, title, ax):\n    widths = np.geomspace(1, 1024, num=75)\n    cwtmatr, freqs = pywt.cwt(\n        data, widths, wavelet, sampling_period=np.diff(time).mean()\n    )\n    cwtmatr = np.abs(cwtmatr[:-1, :-1])\n    pcm = ax.pcolormesh(time, freqs, cwtmatr)\n    ax.set_yscale(\"log\")\n    ax.set_xlabel(\"Time (s)\")\n    ax.set_ylabel(\"Frequency (Hz)\")\n    ax.set_title(title)\n    plt.colorbar(pcm, ax=ax)\n    return ax\n\n# generate signal\ntime = np.linspace(0, 1, 1000)\nchirp1, frequency1 = make_chirp(time, 0.2, 9)\nchirp2, frequency2 = make_chirp(time, 0.1, 5)\nchirp = chirp1 + 0.6 * chirp2\nchirp *= gaussian(time, 0.5, 0.2)\n\n# perform CWT with different wavelets on same signal and plot results\nwavelets = [f\"cmor{x:.1f}-{y:.1f}\" for x in [0.5, 1.5, 2.5] for y in [0.5, 1.0, 1.5]]\nfig, axs = plt.subplots(3, 3, figsize=(10, 10), sharex=True)\nfor ax, wavelet in zip(axs.flatten(), wavelets):\n    plot_wavelet(time, chirp, wavelet, wavelet, ax)\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.suptitle(\"Scalograms of the same signal with different wavelets\")\nplt.show()\n\nFor this example, we will be using a complex Morlet with a bandwidth of 1.5 and a center frequency of 1\n\nbandwidth = 1.5\ncenter_freq = 1\nwavelet_mother = f\"cmor{bandwidth}-{center_freq}\"\nprint(wavelet_mother)\n\n","type":"content","url":"/nino3#define-complex-morlet","position":25},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Applying Wavelets"},"type":"lvl2","url":"/nino3#applying-wavelets","position":26},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Applying Wavelets"},"content":"\n\nscales = np.arange(1, jtot + 1, dj)\nwavelet_coeffs, freqs = pywt.cwt(\n    data=nino3_data, scales=scales, wavelet=wavelet_mother, sampling_period=dt\n)\n\n","type":"content","url":"/nino3#applying-wavelets","position":27},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Power Spectrum"},"type":"lvl2","url":"/nino3#power-spectrum","position":28},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Power Spectrum"},"content":"The power spectrum is the real component of the wavelet coefficients. We can find this value by squaring the absolute value of the wavelet_coeffs to return the magnitude of the real component to make a better graph.\n\npower = np.power((abs(wavelet_coeffs)), 2)\n\nfig, ax = plt.subplots(figsize=(10, 10))\n\n# Plot contour around data\nplt.contour(\n    power, vmax=(power).max(), vmin=(power).min(), levels=10\n)\nplt.contour(power, levels=10, colors=\"k\", linewidths=0.5, alpha=0.75)\n\n# Plot Scalogram\nplt.imshow(\n    power, vmax=(power).max(), vmin=(power).min(), aspect=\"auto\"\n)\n\nplt.xticks(range(len(x_tickrange))[start::display_nth], x_tickrange[start::display_nth])\nplt.title(\"El Niño Wavelet Power Spectrum\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Scale\")\nplt.colorbar()\nplt.show()\n\nThe power spectrum above demonstrates a strong peak (in yellow) at 50 that represents an interesting consistent pattern across the decades of atmosphere data.\n\n","type":"content","url":"/nino3#power-spectrum","position":29},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Phase Spectrum"},"type":"lvl2","url":"/nino3#phase-spectrum","position":30},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Phase Spectrum"},"content":"While less commonly used, the phase spectrum is the imaginary component of the wavelet.\n\n# compare the phase spectrum\nphase = np.angle(wavelet_coeffs)\n\nfig, ax = plt.subplots(figsize=(10, 10))\n\n# Convert Y-Axis from default to symmetrical log (symlog) with labels\nax.set_yscale(\"symlog\")\nax.invert_yaxis()\nax.set_yticks([10, 20, 30, 40, 50])\nax.set_yticklabels([10, 20, 30, 40, 50])\n\n# Plot scalogram\nplt.imshow(\n    phase, vmax=(phase).max(), vmin=(phase).min(), aspect=\"auto\"\n)\n\n# Convert default X-axis from time steps of 0-504 (0-len(sst_data)) to Years\nstart_year = 1871\nend_year = 1871 + (len(nino3_data) * dt)\nx_tickrange = np.arange(start_year, end_year, dt)\nstart = int(9 / dt)  # 36, starts the x-axis label at 1880 (9 years after start of data)\ndisplay_nth = int(20 / dt)  # 80, display x-axis label every 20 years\nplt.xticks(range(len(x_tickrange))[start::display_nth], x_tickrange[start::display_nth])\n\nplt.title(\"El Niño Wavelet Phase Spectrum\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Scale\")\nplt.colorbar()\nplt.show()\n\n\n\n","type":"content","url":"/nino3#phase-spectrum","position":31},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Summary"},"type":"lvl2","url":"/nino3#summary","position":32},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Summary"},"content":"Frequency signals appear in more than just audio! A frequency analysis of weather data can inform us about how weather trends change through a year and over a decades worth of data.","type":"content","url":"/nino3#summary","position":33},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/nino3#whats-next","position":34},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl3":"What’s next?","lvl2":"Summary"},"content":"Learn how more about PyWavelets\n\n","type":"content","url":"/nino3#whats-next","position":35},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Resources and references"},"type":"lvl2","url":"/nino3#resources-and-references","position":36},{"hierarchy":{"lvl1":"Atmospheric Data: Nino 3 SST Index","lvl2":"Resources and references"},"content":"“A Practical Guide to Wavelet Analysis” (Torrence and Compo, 1998)","type":"content","url":"/nino3#resources-and-references","position":37},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/how-to-cite","position":1},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells"},"type":"lvl1","url":"/jingle-bells","position":0},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells"},"content":"\n\n","type":"content","url":"/jingle-bells","position":1},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells"},"type":"lvl1","url":"/jingle-bells#pywavelets-and-jingle-bells","position":2},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells"},"content":"Part 1 for working with audio signals\n\n\n\n","type":"content","url":"/jingle-bells#pywavelets-and-jingle-bells","position":3},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Overview"},"type":"lvl2","url":"/jingle-bells#overview","position":4},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Overview"},"content":"This notebook will generate a wavelet scalogram to determine the order of notes in a short .wav file. You’ll learn how to generate a Wavelet Power spectrum graph\n\nPrerequisites\n\nBackground\n\nPyWavelets Overview\n\nWavelet Power Spectrum\n\n","type":"content","url":"/jingle-bells#overview","position":5},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Prerequisites"},"type":"lvl2","url":"/jingle-bells#prerequisites","position":6},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Matplotlib\n\nNecessary\n\nUsed to plot data\n\nIntro to Pandas\n\nNecessary\n\nUsed to read in and organize data (in particular dataframes)\n\nIntro to Numpy\n\nNecessary\n\nUsed to work with large arrays\n\nIntro to SciPy\n\nHelpful\n\nUsed to work with .wav files and built-in Fast Fourier Transform\n\nTime to learn: 20 minutes\n\n\n\n","type":"content","url":"/jingle-bells#prerequisites","position":7},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Background"},"type":"lvl2","url":"/jingle-bells#background","position":8},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Background"},"content":"Wavelet analysis is accomplished in Python via external package. \n\nPyWavelets is an open source Python package for wavelet analysis\n\nEither with pip install:pip install PyWavelets\n\nOr with condaconda install pywavelets\n\n","type":"content","url":"/jingle-bells#background","position":9},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Imports"},"type":"lvl2","url":"/jingle-bells#imports","position":10},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Imports"},"content":"\n\nimport numpy as np                          # working with arrays\nimport pandas as pd                         # working with dataframes\nfrom scipy.io import wavfile                # loading in wav files\nimport matplotlib.pyplot as plt             # plot data\nfrom scipy.fftpack import fft, fftfreq      # working with Fourier Transforms\n\nimport pywt                                 # PyWavelets\n\n","type":"content","url":"/jingle-bells#imports","position":11},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"PyWavelets Overview"},"type":"lvl2","url":"/jingle-bells#pywavelets-overview","position":12},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"PyWavelets Overview"},"content":"PyWavelets returns both the coefficients and frequency information for wavelets from the input datacoeffs, frequencies = pywt.cwt(data, scales, wavelet, sampling_period)\n\n","type":"content","url":"/jingle-bells#pywavelets-overview","position":13},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl3":"Input Values","lvl2":"PyWavelets Overview"},"type":"lvl3","url":"/jingle-bells#input-values","position":14},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl3":"Input Values","lvl2":"PyWavelets Overview"},"content":"The \n\nContinuous Wavelet Transform (CWT) in PyWavelets accepts multiple input values:\n\nRequired:\n\ndata: input data (as an array)\n\nwavelet: name of the Mother wavelet\n\nscales: collection of the scales to use will determine the range which the wavelet will be stretched or squished\n\nOptional:\n\nsampling_period: sampling period for frequencies output. Scales are not scaled by the period (and coefficients are independent of the sampling_period)\n\n","type":"content","url":"/jingle-bells#input-values","position":15},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl3":"Return Values","lvl2":"PyWavelets Overview"},"type":"lvl3","url":"/jingle-bells#return-values","position":16},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl3":"Return Values","lvl2":"PyWavelets Overview"},"content":"The continuous wavelet transforms in PyWavelets returns two values:\n\ncoefficients: collection of complex number outputs for wavelet coefficients\n\nfrequencies: collection of frequencies (if the sampling period are in seconds then frequencies are in hertz otherwise a sampling period of 1 is assumed)\n\nThe final size of coefficients depends on the length of the input data and the length of the given scales.\n\n","type":"content","url":"/jingle-bells#return-values","position":17},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl3":"Choosing a Scale","lvl2":"PyWavelets Overview"},"type":"lvl3","url":"/jingle-bells#choosing-a-scale","position":18},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl3":"Choosing a Scale","lvl2":"PyWavelets Overview"},"content":"","type":"content","url":"/jingle-bells#choosing-a-scale","position":19},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl4":"Scales vs. Frequency","lvl3":"Choosing a Scale","lvl2":"PyWavelets Overview"},"type":"lvl4","url":"/jingle-bells#scales-vs-frequency","position":20},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl4":"Scales vs. Frequency","lvl3":"Choosing a Scale","lvl2":"PyWavelets Overview"},"content":"The range of scales are a combination of the smallest scale (s0), spacing between discrete scales (dj), and the maximum scale (jtot).\n\nFor the purpose of this exercise, the musical range of frequencies range from 261 - 494 Hz.\n\nNote\n\nFreq\n\nA note\n\n440 hz\n\nB note\n\n494 hz\n\nC note\n\n261 hz\n\nD note\n\n293 hz\n\nE note\n\n330 hz\n\nF note\n\n350 hz\n\nG note\n\n392 hz\n\nNote: Musical note frequencies can vary, these frequencies are taken from \n\nhere\n\nIt is good practice to include a range greater than precisely needed. This will make the bands for each frequency in the wavelets clearer.\n\nScales will change the shape of the wavelet to have it match a specific frequency. For example, scalings from 1 to 40 represent a frequency range from 8125 - 208.33 Hz.sample_rate, signal_data = wavfile.read('jingle_bells.wav')\nscales = np.arange(1, 40)\nwavelet_coeffs, freqs = pywt.cwt(signal_data, scales, wavelet = \"morl\")\n\n","type":"content","url":"/jingle-bells#scales-vs-frequency","position":21},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Extract audio .wav file"},"type":"lvl2","url":"/jingle-bells#extract-audio-wav-file","position":22},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Extract audio .wav file"},"content":"The .wav input file contains information about the amplitude at every time step (in seconds) in the file. The frequency will determine which note each part of the piece represents.\n\nsampleRate, signalData = wavfile.read(\"../data/jingle_bells.wav\")\n\nduration = len(signalData) / sampleRate\ntime = np.arange(0, duration, 1/sampleRate) \n\nprint(f\"Sample Rate: {sampleRate}\")\nprint(f\"duration = {duration} seconds\")\nprint(f\"Total Length in time steps = {len(time)}\")\n\n","type":"content","url":"/jingle-bells#extract-audio-wav-file","position":23},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Let’s Give the Data a Look!"},"type":"lvl2","url":"/jingle-bells#lets-give-the-data-a-look","position":24},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Let’s Give the Data a Look!"},"content":"It is always good practice to view the data that we have collected. First, let’s organize the data into a pandas dataframe to organize the amplitude and time stamps.\n\nsignal_df = pd.DataFrame({'time (seconds)': time, 'amplitude': signalData})\nsignal_df.head()\n\n","type":"content","url":"/jingle-bells#lets-give-the-data-a-look","position":25},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl3":"Plot a Small Sample of the .wav File","lvl2":"Let’s Give the Data a Look!"},"type":"lvl3","url":"/jingle-bells#plot-a-small-sample-of-the-wav-file","position":26},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl3":"Plot a Small Sample of the .wav File","lvl2":"Let’s Give the Data a Look!"},"content":"Plot a small subsample of the .wav to visualize the input data.\n\nfig, ax = plt.subplots(figsize=(8, 8))\nfig = plt.plot(signal_df[\"time (seconds)\"], signal_df[\"amplitude\"])\nplt.title(\"Subsample of \\\"Jingle Bells\\\" Audio File\")\nax.set_xlim(signal_df[\"time (seconds)\"][2000], signal_df[\"time (seconds)\"][3000])\nplt.xlabel(\"Time (seconds)\")\nplt.ylabel(\"Amplitude\")\nplt.show()\n\n","type":"content","url":"/jingle-bells#plot-a-small-sample-of-the-wav-file","position":27},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Power Spectrum"},"type":"lvl2","url":"/jingle-bells#power-spectrum","position":28},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Power Spectrum"},"content":"\n\nwavelet_coeffs is a complex number with a real and an imaginary part (1 + 2i). The power spectrum plots the real component of the complex number. The real component represents the magnitude of the wavelet coefficient displayed as the absolute value of the coefficients squared.\n\nwavelet_mother = \"morl\" # morlet mother wavelet\n\n# scale determines how squished or stretched a wavelet is\nscales = np.arange(1, 40)\nwavelet_coeffs, freqs = pywt.cwt(signalData, scales, wavelet = wavelet_mother)\n\n# Shape of wavelet transform\nprint(f\"size {wavelet_coeffs.shape} with {wavelet_coeffs.shape[0]} scales and {wavelet_coeffs.shape[1]} time steps\")\nprint(f\"x-axis be default is: {wavelet_coeffs.shape[1]}\")\nprint(f\"y-axis be default is: {wavelet_coeffs.shape[0]}\")\n\n","type":"content","url":"/jingle-bells#power-spectrum","position":29},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl3":"A Note on Choosing the Right Scales","lvl2":"Power Spectrum"},"type":"lvl3","url":"/jingle-bells#a-note-on-choosing-the-right-scales","position":30},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl3":"A Note on Choosing the Right Scales","lvl2":"Power Spectrum"},"content":"freqs is normalized frequencies, so it needs to be multiplied by this sampling frequency to turn it back into frequencies which means that you need to multiply them by your sampling frequency (500Hz) to turn them into actual frequencies.\n\nwavelet_mother = \"morl\" # morlet mother wavelet\n\n# scale determines how squished or stretched a wavelet is\nscales = np.arange(1, 40)\nwavelet_coeffs, freqs = pywt.cwt(signalData, scales, wavelet = wavelet_mother)\n\nplt.axhline(y=440, color='lightpink', linestyle='--', label='A') # A note: 440 hz\nplt.axhline(y=494, color=\"lightblue\", linestyle='--', label='B') # B Note: 494 hz\nplt.axhline(y=261, color='red', linestyle='--', label='C')       # C Note: 261 hz\nplt.axhline(y=293, color='green', linestyle='--', label='D')     # D Note: 293 hz\nplt.axhline(y=330, color='orange', linestyle='--', label='E')    # E Note: 330 hz\nplt.axhline(y=350, color='grey', linestyle='--', label='F')      # F Note: 350 hz\nplt.axhline(y=392, color='purple', linestyle='--', label='G')    # G Note: 392 hz\n\nplt.xlabel(\"Scale\")\nplt.ylabel(\"Frequency (Hz)\")\nprint(f\"Frequency in Hz:\\n{freqs*sampleRate}\")\nplt.plot(freqs*sampleRate)\n\n","type":"content","url":"/jingle-bells#a-note-on-choosing-the-right-scales","position":31},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Plot scalogram"},"type":"lvl2","url":"/jingle-bells#plot-scalogram","position":32},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Plot scalogram"},"content":"The scalogram will visually display the strength of the frequency at a particular time interval. A stronger signal in red represents a wavelet that strongly matches a specific frequency in that range, while blue represents where the wavelet has a weaker match to a specific frequency. The best match for a note will be found where the signal is strongest.\n\nfig, ax = plt.subplots(figsize=(8, 8))\ndata = np.log2(np.square(abs(wavelet_coeffs))) # compare the magnitude\nplt.xlabel(\"Time Steps\")\nplt.ylabel(\"Scale Sensitivity\")\nplt.imshow(data, \n           vmax=(data).max(), vmin=(data).min(),\n           cmap=\"coolwarm\", aspect=\"auto\")\nplt.colorbar()\nplt.show()\n\n","type":"content","url":"/jingle-bells#plot-scalogram","position":33},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Overlay Possible Frequencies"},"type":"lvl2","url":"/jingle-bells#overlay-possible-frequencies","position":34},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Overlay Possible Frequencies"},"content":"To overlay these frequencies with the wavelet scalogram:\n\nImportant NoteTo convert HZ frequency to a scale = hz *.0001 (where 0.01 is 100 Hz sampling) then apply frequency2scale() PyWavelets function\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\n# Overlay frequency of notes as dotted lines\nsample_rate = 1/sampleRate\na_freq = pywt.frequency2scale(wavelet_mother, 440*sample_rate)\nplt.axhline(y=a_freq, color='lightpink', linestyle='--', label='A') # A note: 440 hz\nb_freq = pywt.frequency2scale(wavelet_mother, 494*sample_rate)\nplt.axhline(y=b_freq, color=\"lightblue\", linestyle='--', label='B') # B Note: 494 hz\nc_freq = pywt.frequency2scale(wavelet_mother, 261*sample_rate)\nplt.axhline(y=c_freq, color='red', linestyle='--', label='C')       # C Note: 261 hz\nd_freq = pywt.frequency2scale(wavelet_mother, 293*sample_rate)\nplt.axhline(y=d_freq, color='green', linestyle='--', label='D')     # D Note: 293 hz\ne_freq = pywt.frequency2scale(wavelet_mother, 330*sample_rate)\nplt.axhline(y=e_freq, color='orange', linestyle='--', label='E')    # E Note: 330 hz\nf_freq = pywt.frequency2scale(wavelet_mother, 350*sample_rate)\nplt.axhline(y=f_freq, color='grey', linestyle='--', label='F')      # F Note: 350 hz\ng_freq = pywt.frequency2scale(wavelet_mother, 392*sample_rate)\nplt.axhline(y=g_freq, color='purple', linestyle='--', label='G')    # G Note: 392 hz\n\n# Plot Power scalogram\npower = np.log2(np.square(abs(wavelet_coeffs))) # compare the magntiude\nplt.title(\"Note Frequency as Scale\")\nplt.xlabel(\"Time Steps\")\nplt.ylabel(\"Scale Sensitivity\")\nplt.imshow(power, \n           vmax=(power).max(), vmin=(power).min(),\n           cmap=\"coolwarm\", aspect=\"auto\")\nplt.legend()\nplt.show()\n\n","type":"content","url":"/jingle-bells#overlay-possible-frequencies","position":35},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Determining Which Frequencies to Overlay"},"type":"lvl2","url":"/jingle-bells#determining-which-frequencies-to-overlay","position":36},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Determining Which Frequencies to Overlay"},"content":"For this example, we know that the input data is “Jingle Bells” so we know which notes are going to be used.\"Jingle Bells, Jingle Bells, Jingle All the Way\" as EEE EEE EGCDE\n\nHowever, let’s imagine that we aren’t sure. Wavelets gain information about when a frequency occurs, but at a lower resolution to an exact frequency. To determine which notes are a best fit, you can make use of FFT to determinine which notes to include. Without FFT, the larger possible ranges of frequency can make it possible to confuse nearby notes.\n\n","type":"content","url":"/jingle-bells#determining-which-frequencies-to-overlay","position":37},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl3":"Fast Fourier Transform","lvl2":"Determining Which Frequencies to Overlay"},"type":"lvl3","url":"/jingle-bells#fast-fourier-transform","position":38},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl3":"Fast Fourier Transform","lvl2":"Determining Which Frequencies to Overlay"},"content":"\n\nfourier_transform = abs(fft(signalData))\nfreqs = fftfreq(len(fourier_transform), sample_rate)\n\nfig, ax = plt.subplots(figsize=(8, 8))\nplt.plot(freqs, fourier_transform)\nax.set_xlim(left=200, right=500) \nplt.axvline(x=261, color=\"red\", label=\"C\",alpha=0.5)    # C Note: 261 hz\nplt.axvline(x=293, color=\"green\", label=\"D\",alpha=0.5)  # D Note: 293 hz\nplt.axvline(x=330, color=\"orange\", label=\"E\",alpha=0.5) # E Note: 330 hz\nplt.axvline(x=391, color=\"purple\", label=\"G\",alpha=0.5) # G Note: 391 hz\nplt.title(\"Signal Frequency Prevalence (FFT)\")\nplt.xlabel('Frequency (Hz)')\nplt.ylabel('Amplitude')\nplt.legend()\nplt.show()\n\n","type":"content","url":"/jingle-bells#fast-fourier-transform","position":39},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Overlay Frequency of Notes"},"type":"lvl2","url":"/jingle-bells#overlay-frequency-of-notes","position":40},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Overlay Frequency of Notes"},"content":"Using FFT we can now say that there are four clear frequencies that are associated with four notes for CDEG.\n\n","type":"content","url":"/jingle-bells#overlay-frequency-of-notes","position":41},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Fast Fourier Transform Predicts Four Notes"},"type":"lvl2","url":"/jingle-bells#fast-fourier-transform-predicts-four-notes","position":42},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Fast Fourier Transform Predicts Four Notes"},"content":"FFT predicts an output with four notes:C, D, E, G\n\nLet’s plot the notes!\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\n# Overlay frequency of notes as dotted lines\nsample_rate = 1/sampleRate\nc_freq = pywt.frequency2scale(wavelet_mother, 261*sample_rate)\nplt.axhline(y=c_freq, color='red', linestyle='--', label='C')       # C Note: 261 hz\nd_freq = pywt.frequency2scale(wavelet_mother, 293*sample_rate)\nplt.axhline(y=d_freq, color='green', linestyle='--', label='D')     # D Note: 293 hz\ne_freq = pywt.frequency2scale(wavelet_mother, 330*sample_rate)\nplt.axhline(y=e_freq, color='orange', linestyle='--', label='E')    # E Note: 330 hz\ng_freq = pywt.frequency2scale(wavelet_mother, 392*sample_rate)\nplt.axhline(y=g_freq, color='purple', linestyle='--', label='G')    # G Note: 392 hz\n\n# Plot Power scalogram\npower = np.log2(np.square(abs(wavelet_coeffs))) # compare the magntiude\nplt.title(\"Note Frequency as Scale\")\nplt.xlabel(\"Time Steps\")\nplt.ylabel(\"Scale Sensitivity\")\nplt.imshow(power, \n           vmax=(power).max(), vmin=(power).min(),\n           cmap=\"coolwarm\", aspect=\"auto\")\nplt.legend()\nplt.show()\n\n","type":"content","url":"/jingle-bells#fast-fourier-transform-predicts-four-notes","position":43},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Four Notes!"},"type":"lvl2","url":"/jingle-bells#four-notes","position":44},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Four Notes!"},"content":"The darkest color correlates with the frequency at each time stamp. Rather than appearing as distinct peaks like a Fourier Transform, wavelets return a gradient of frequencies. This is the loss in precision due to Heisenberg’s Uncertainty Principle. While the frequencies can still be determined, there is some level of uncertainty in the exact frequencies. This is where combining wavelets with a Fourier Transform can be useful. We now know that this piece has four notes CDEG. The vertical bands represent where the note ends before the next note begins. This piece of music has a deliberate start and stop so this band will not always be as obvious in other pieces of music.\n\nWe can read this wavelet analysis by finding what note corresponds with the darkest band.\n\nWe should now have the order of the notes, read from left to right:","type":"content","url":"/jingle-bells#four-notes","position":45},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl3":"EEE EEE EGCDE","lvl2":"Four Notes!"},"type":"lvl3","url":"/jingle-bells#eee-eee-egcde","position":46},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl3":"EEE EEE EGCDE","lvl2":"Four Notes!"},"content":"\n\n\n\n","type":"content","url":"/jingle-bells#eee-eee-egcde","position":47},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Summary"},"type":"lvl2","url":"/jingle-bells#summary","position":48},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl2":"Summary"},"content":"Wavelets can report on both the frequency and time a frequency occurs. However, due to Heisenberg’s Uncertainty Principle, by gaining resolution on time, some resolution on frequency is lost. It can be helpful to incorporate both a Fourier Transform and a Wavelet analysis to a signal to help determine the possible ranges of expected frequencies. PyWavelets is a free open-source package for wavelets in Python.","type":"content","url":"/jingle-bells#summary","position":49},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/jingle-bells#whats-next","position":50},{"hierarchy":{"lvl1":"PyWavelets and Jingle Bells","lvl3":"What’s next?","lvl2":"Summary"},"content":"Up next: apply wavelets transform to determine the frequency and order of an unknown input!","type":"content","url":"/jingle-bells#whats-next","position":51},{"hierarchy":{"lvl1":"Spy Keypad"},"type":"lvl1","url":"/spy-keypad","position":0},{"hierarchy":{"lvl1":"Spy Keypad"},"content":"\n\n","type":"content","url":"/spy-keypad","position":1},{"hierarchy":{"lvl1":"Spy Keypad"},"type":"lvl1","url":"/spy-keypad#spy-keypad","position":2},{"hierarchy":{"lvl1":"Spy Keypad"},"content":"Part 2 for working with audio signals\n\n\n\n","type":"content","url":"/spy-keypad#spy-keypad","position":3},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Overview"},"type":"lvl2","url":"/spy-keypad#overview","position":4},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Overview"},"content":"A door is encoded with a number pad (0-9). We can’t see the door, but through nefarious means we have a recording of someone opening it. Quick! We need to decode this \n\nmystery signal and the order they appear to open the door!\n\nWe know that the door code is set up as:\n\nA note: 0\n\nB note: 1\n\nC note: 2\n\nD note: 3\n\nE note: 4\n\nF note: 5\n\n","type":"content","url":"/spy-keypad#overview","position":5},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Prerequisites"},"type":"lvl2","url":"/spy-keypad#prerequisites","position":6},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Matplotlib\n\nNecessary\n\nUsed to plot data\n\nIntro to Pandas\n\nNecessary\n\nUsed to read in and organize data (in particular dataframes)\n\nIntro to Numpy\n\nNecessary\n\nUsed to work with large arrays\n\nIntro to SciPy\n\nHelpful\n\nUsed to work with .wav files and built-in Fast Fourier Transform\n\nTime to learn: 30 minutes\n\n\n\n","type":"content","url":"/spy-keypad#prerequisites","position":7},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Imports"},"type":"lvl2","url":"/spy-keypad#imports","position":8},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Imports"},"content":"\n\nimport numpy as np                          # working with arrays\nimport pandas as pd                         # working with dataframes\nfrom scipy.io import wavfile                # loading in wav files\nimport matplotlib.pyplot as plt             # plot data\nfrom scipy.fftpack import fft, fftfreq      # working with Fourier Transforms\n\nimport pywt                                 # PyWavelets\n\n","type":"content","url":"/spy-keypad#imports","position":9},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Extract audio .wav file"},"type":"lvl2","url":"/spy-keypad#extract-audio-wav-file","position":10},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Extract audio .wav file"},"content":"As when working with the “Jingle Bells” song file, any .wav input file contains information about the amplitude at every point in the file. The frequency of the note will determine which chord each part of the piece represents.\n\nsampleRate, signalData = wavfile.read('../data/mystery_signal.wav')\n\nduration = len(signalData) / sampleRate\ntime = np.arange(0, duration, 1/sampleRate) \n\nprint(f\"Sample Rate: {sampleRate}\")\nprint(f\"duration = {duration} seconds\")\nprint(f\"Total length in time steps = {len(time)}\")\n\n","type":"content","url":"/spy-keypad#extract-audio-wav-file","position":11},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Let’s Give the Data a Look!"},"type":"lvl2","url":"/spy-keypad#lets-give-the-data-a-look","position":12},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Let’s Give the Data a Look!"},"content":"It is always good practice to view the data that we have collected. First, let’s organize the data into a pandas dataframe to organize the amplitude and time stamps.\n\nsignal_df = pd.DataFrame({'time (seconds)': time, 'amplitude': signalData})\nsignal_df.head()\n\n","type":"content","url":"/spy-keypad#lets-give-the-data-a-look","position":13},{"hierarchy":{"lvl1":"Spy Keypad","lvl3":"Plot a Small Sample of the .wav File","lvl2":"Let’s Give the Data a Look!"},"type":"lvl3","url":"/spy-keypad#plot-a-small-sample-of-the-wav-file","position":14},{"hierarchy":{"lvl1":"Spy Keypad","lvl3":"Plot a Small Sample of the .wav File","lvl2":"Let’s Give the Data a Look!"},"content":"Plot a small subsample of the .wav to visualize the input data.\n\nfig, ax = plt.subplots(figsize=(8, 8))\nfig = plt.plot(signal_df[\"time (seconds)\"], signal_df[\"amplitude\"])\nplt.title(\"Subsample of Mystery Audio File\")\nax.set_xlim(signal_df[\"time (seconds)\"][2000], signal_df[\"time (seconds)\"][4000])\nplt.xlabel(\"Time (seconds)\")\nplt.ylabel(\"Amplitude\")\nplt.show()\n\n","type":"content","url":"/spy-keypad#plot-a-small-sample-of-the-wav-file","position":15},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Wavelet Analysis: Power Spectrum"},"type":"lvl2","url":"/spy-keypad#wavelet-analysis-power-spectrum","position":16},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Wavelet Analysis: Power Spectrum"},"content":"The power spectrum plots the real component of the complex number returns from wavelet coefficients. This will return information about the frequency and time that we need to use to determine which notes are used in what order for the keypad.\n\nFor the purpose of this example, we will use the Morlet mother wavelet. Morlet is one type of mother wavelet useful for working with audio signals and is a good general wavelet to start with when analyzing frequencies of a signal.\n\nHowever, choosing which wavelet to use is an important step as different wavelets will be sensitive to different features in time-series data.\n\nTo learn more!\n\nwavelet_mother = \"morl\" # morlet mother wavelet\n\n# scale determines how squished or stretched a wavelet is\nscales = np.arange(1, 40)\nwavelet_coeffs, freqs = pywt.cwt(signalData, scales, wavelet = wavelet_mother)\n\n# Shape of wavelet transform\nprint(f\"size {wavelet_coeffs.shape} with {wavelet_coeffs.shape[0]} scales and {wavelet_coeffs.shape[1]} time steps\")\nprint(f\"x-axis is: {wavelet_coeffs.shape[1]}\")\nprint(f\"y-axis is: {wavelet_coeffs.shape[0]}\")\n\n","type":"content","url":"/spy-keypad#wavelet-analysis-power-spectrum","position":17},{"hierarchy":{"lvl1":"Spy Keypad","lvl4":"Plot Scalogram","lvl2":"Wavelet Analysis: Power Spectrum"},"type":"lvl4","url":"/spy-keypad#plot-scalogram","position":18},{"hierarchy":{"lvl1":"Spy Keypad","lvl4":"Plot Scalogram","lvl2":"Wavelet Analysis: Power Spectrum"},"content":"We will be plotting the wavelet as a scalogram, where the presence of a strong match to a specific frequency will be a darker color. This will create distinct bands of a dark color where a specific frequency is present.\n\nfig, ax = plt.subplots(figsize=(8, 8))\ndata = np.log2(np.square(abs(wavelet_coeffs))) # compare the magntiude\nplt.xlabel(\"Time Steps\")\nplt.ylabel(\"Scale Sensitivity\")\nplt.imshow(data, \n           vmax=(data).max(), vmin=(data).min(),\n           cmap=\"coolwarm\", aspect=\"auto\")\nplt.colorbar()\nplt.show()\n\n","type":"content","url":"/spy-keypad#plot-scalogram","position":19},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Behold! Distinct Bands of Frequencies!"},"type":"lvl2","url":"/spy-keypad#behold-distinct-bands-of-frequencies","position":20},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Behold! Distinct Bands of Frequencies!"},"content":"Each distinct band represents a note. So, we can see that the data at the beginning and at the end is random noise, with no distinct frequency. But at 1 second, a distinct note that lasts for 1 second, followed by three additional distinct bands. We now know the code is four numbers long. But now we need to determine what the numbers are and what their order is. Let’s see where the possible note frequencies we have by overlaying the frequencies of each note onto the wavelet scalogram.\n\nImportant NoteTo convert Hz frequency to a scale = hz *.0001 (where 0.01 is 100 Hz sampling) then apply frequency2scale PyWavelets function\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\n# Overlay frequency of notes as dotted lines\nsample_rate = 1/sampleRate\na_freq = pywt.frequency2scale(wavelet_mother, 440*sample_rate)\nplt.axhline(y=a_freq, color='lightpink', linestyle='--', label='A') # A note: 440 hz\nb_freq = pywt.frequency2scale(wavelet_mother, 494*sample_rate)\nplt.axhline(y=b_freq, color=\"blue\", linestyle='--', label='B')      # B Note: 494 hz\nc_freq = pywt.frequency2scale(wavelet_mother, 261*sample_rate)\nplt.axhline(y=c_freq, color='lightblue', linestyle='--', label='C') # C Note: 261 hz\nd_freq = pywt.frequency2scale(wavelet_mother, 293*sample_rate)\nplt.axhline(y=d_freq, color='green', linestyle='--', label='D')     # D Note: 293 hz\ne_freq = pywt.frequency2scale(wavelet_mother, 330*sample_rate)\nplt.axhline(y=e_freq, color='orange', linestyle='--', label='E')    # E Note: 330 hz\nf_freq = pywt.frequency2scale(wavelet_mother, 350*sample_rate)\nplt.axhline(y=f_freq, color='grey', linestyle='--', label='F')      # F Note: 350 hz\ng_freq = pywt.frequency2scale(wavelet_mother, 392*sample_rate)\nplt.axhline(y=g_freq, color='purple', linestyle='--', label='G')    # G Note: 392 hz\n\n# Plot Power scalogram\npower = np.log2(np.square(abs(wavelet_coeffs))) # compare the magntiude\nplt.title(\"Note Frequency as Scale\")\nplt.xlabel(\"Time Steps\")\nplt.ylabel(\"Scale Sensitivity\")\nplt.imshow(power, \n           vmax=(power).max(), vmin=(power).min(),\n           cmap=\"coolwarm\", aspect=\"auto\")\nplt.legend()\nplt.show()\n\n","type":"content","url":"/spy-keypad#behold-distinct-bands-of-frequencies","position":21},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"But Which Match Best?"},"type":"lvl2","url":"/spy-keypad#but-which-match-best","position":22},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"But Which Match Best?"},"content":"We are looking for a note frequency that best lines up with the darkest part of each band. The first and the last band seem like the same note, but is it closer to an A note or a B note?\n\nLet’s see if we can use Fourier Transform to get a smaller range of notes to chose from.\n\n","type":"content","url":"/spy-keypad#but-which-match-best","position":23},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Fast Fourier Transform"},"type":"lvl2","url":"/spy-keypad#fast-fourier-transform","position":24},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Fast Fourier Transform"},"content":"\n\nfourier_transform = abs(fft(signalData))\nfreqs = fftfreq(len(fourier_transform), sample_rate)\n\nfig, ax = plt.subplots(figsize=(8, 8))\nplt.plot(freqs, fourier_transform)\nax.set_xlim(left=200, right=500) \nplt.axvline(x=440, color=\"lightpink\", label=\"A\",alpha=0.5) # A note: 440 hz\nplt.axvline(x=494, color=\"blue\", label=\"B\",alpha=0.5)      # B Note: 494 hz\nplt.axvline(x=261, color=\"lightblue\", label=\"C\",alpha=0.5) # C Note: 261 hz\nplt.axvline(x=293, color=\"green\", label=\"D\",alpha=0.5)     # D Note: 293 hz\nplt.axvline(x=330, color=\"orange\", label=\"E\",alpha=0.5)    # E Note: 330 hz\nplt.axvline(x=350, color=\"grey\", label=\"F\",alpha=0.5)      # F Note: 350 hz\nplt.axvline(x=392, color=\"purple\", label=\"G\",alpha=0.5)    # G Note: 392 hz\nplt.title(\"Signal Frequency Prevalence (FFT)\")\nplt.xlabel('Frequency (Hz)')\nplt.ylabel('Amplitude')\nplt.legend()\nplt.show()\n\n","type":"content","url":"/spy-keypad#fast-fourier-transform","position":25},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Perfect, There are Three Notes!"},"type":"lvl2","url":"/spy-keypad#perfect-there-are-three-notes","position":26},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Perfect, There are Three Notes!"},"content":"Three notes stand out, and one note is used about twice as much as the other two: A, B, F.\n\nfig, ax = plt.subplots(figsize=(8, 8))\n\n# Overlay frequency of notes as dotted lines\nsample_rate = 1/sampleRate\na_freq = pywt.frequency2scale(wavelet_mother, 440*sample_rate)\nplt.axhline(y=a_freq, color='cyan', linestyle='--', label='A')\nb_freq = pywt.frequency2scale(wavelet_mother, 494*sample_rate)\nplt.axhline(y=b_freq, color=\"green\", linestyle='--', label='B')\nf_freq = pywt.frequency2scale(wavelet_mother, 350*sample_rate)\nplt.axhline(y=f_freq, color='grey', linestyle='--', label='F')\n\n# Plot Power scalogram\npower = np.log2(np.square(abs(wavelet_coeffs))) # compare the magnitude\nplt.title(\"Note Frequency as Scale\")\nplt.xlabel(\"Time Steps\")\nplt.ylabel(\"Scale Sensitivity\")\nplt.imshow(power, \n           vmax=(power).max(), vmin=(power).min(),\n           cmap=\"coolwarm\", aspect=\"auto\")\nplt.legend()\nplt.show()\n\n","type":"content","url":"/spy-keypad#perfect-there-are-three-notes","position":27},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Three Notes Played Over Six Seconds"},"type":"lvl2","url":"/spy-keypad#three-notes-played-over-six-seconds","position":28},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Three Notes Played Over Six Seconds"},"content":"We have the keypad solution! The three notes are played (sometimes repeated) over the course of the six seconds.","type":"content","url":"/spy-keypad#three-notes-played-over-six-seconds","position":29},{"hierarchy":{"lvl1":"Spy Keypad","lvl3":"A, B, F, A","lvl2":"Three Notes Played Over Six Seconds"},"type":"lvl3","url":"/spy-keypad#a-b-f-a","position":30},{"hierarchy":{"lvl1":"Spy Keypad","lvl3":"A, B, F, A","lvl2":"Three Notes Played Over Six Seconds"},"content":"From our original problem, we know that the door code is set up as:\n\nA note: 0\n\nB note: 1\n\nC note: 2\n\nD note: 3\n\nE note: 4\n\nF note: 5\n\nThe solution to the door password is:","type":"content","url":"/spy-keypad#a-b-f-a","position":31},{"hierarchy":{"lvl1":"Spy Keypad","lvl3":"0, 1, 5, 0","lvl2":"Three Notes Played Over Six Seconds"},"type":"lvl3","url":"/spy-keypad#id-0-1-5-0","position":32},{"hierarchy":{"lvl1":"Spy Keypad","lvl3":"0, 1, 5, 0","lvl2":"Three Notes Played Over Six Seconds"},"content":"\n\n\n\n","type":"content","url":"/spy-keypad#id-0-1-5-0","position":33},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Summary"},"type":"lvl2","url":"/spy-keypad#summary","position":34},{"hierarchy":{"lvl1":"Spy Keypad","lvl2":"Summary"},"content":"Now we’ve had a chance to work with unknown input values, but within an expected range. Different time-series data will have different ranges of expected frequencies, and with Fourier Transform and wavelet analysis it is possible to pull out such relevant data.","type":"content","url":"/spy-keypad#summary","position":35},{"hierarchy":{"lvl1":"Spy Keypad","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/spy-keypad#whats-next","position":36},{"hierarchy":{"lvl1":"Spy Keypad","lvl3":"What’s next?","lvl2":"Summary"},"content":"Up next: apply wavelets transform and work with weather data!","type":"content","url":"/spy-keypad#whats-next","position":37},{"hierarchy":{"lvl1":"Wavelet Basics"},"type":"lvl1","url":"/wavelet-basics","position":0},{"hierarchy":{"lvl1":"Wavelet Basics"},"content":"\n\n","type":"content","url":"/wavelet-basics","position":1},{"hierarchy":{"lvl1":"Wavelet Basics"},"type":"lvl1","url":"/wavelet-basics#wavelet-basics","position":2},{"hierarchy":{"lvl1":"Wavelet Basics"},"content":"\n\n\n\n","type":"content","url":"/wavelet-basics#wavelet-basics","position":3},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Overview"},"type":"lvl2","url":"/wavelet-basics#overview","position":4},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Overview"},"content":"Prerequistites\n\nBackground\n\nLoad .wav File for Audio\n\nFourier Transform - Frequency, but not Time\n\nWavelet Transform - Frequency and Time\n\nWavelet Terminology\n\n","type":"content","url":"/wavelet-basics#overview","position":5},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Prerequisites"},"type":"lvl2","url":"/wavelet-basics#prerequisites","position":6},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Prerequisites"},"content":"Concepts\n\nImportance\n\nNotes\n\nIntro to Matplotlib\n\nNecessary\n\nUsed to plot data\n\nIntro to Pandas\n\nNecessary\n\nUsed to read in and organize data (in particular dataframes)\n\nIntro to Numpy\n\nNecessary\n\nUsed to work with large arrays\n\nIntro to SciPy\n\nHelpful\n\nUsed to work with .wav files and built-in Fast Fourier Transform\n\nTime to learn: 45 minutes\n\n","type":"content","url":"/wavelet-basics#prerequisites","position":7},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Background"},"type":"lvl2","url":"/wavelet-basics#background","position":8},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Background"},"content":"Time-series data refers to data recorded in successive time intervals. For example, imagine a short piece of music. Each note in the piece can be any note from A to G and varies based on frequency to produce different pitches. A higher frequency is associated with a higher pitch, like an A note, while a lower frequency is associated with a lower pitch, like a C note.\n\nFourier Transform is a common tool to analyze and pull out which frequencies are present in a signal. With tools like Fourier Transform, we can easily distinguish and determine if a B and a D note appear in the piece of music. However, this does not encapulsate all the information from a signal.\n\nMost importantly, what is the order?\n\nThe musical piece “BDDB” is very different from “DDDDBD” while they both share the same notes B and D. The time and order of data is lost when relying only on signal processing tools like Fourier Transform. Wavelets offer a powerful opportunity for signal analysis to return both information about the frequency and information about the time when the frequency occurred.\n\n\n\n","type":"content","url":"/wavelet-basics#background","position":9},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Imports"},"type":"lvl2","url":"/wavelet-basics#imports","position":10},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Imports"},"content":"\n\nimport pywt                                 # PyWavelets\nimport numpy as np                          # working with arrays\nimport pandas as pd                         # working with dataframes\nfrom scipy.io import wavfile                # loading in .wav files\nimport matplotlib.pyplot as plt             # plot data (fourier transform and wav files)\nfrom scipy.fftpack import fft, fftfreq      # working with Fourier Transforms\n\n\n\n","type":"content","url":"/wavelet-basics#imports","position":11},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Load .wav File for Audio"},"type":"lvl2","url":"/wavelet-basics#load-wav-file-for-audio","position":12},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Load .wav File for Audio"},"content":"\n\nFor this example, we will be using a short .wav file (\n\njingle_bells.wav) that contains the first few notes of “Jingle Bells”.\n\nJingle Bells is a simple musical piece that is taught to beginners and children since it can be entirely played with one hand on the piano. For the purpose of this example, we will be analyzing the first three lines of “Jingle Bells”:\"Jingle Bells, Jingle Bells, Jingle All the Way\" as EEE EEE EGCDE\n\nWe can load in the jingle_bell.wav file with the scipy.io.wavfile() function. This scipy function will return both the sample rate of the data and the frequency of the data.\n\nThe length of the .wav file can be determined as a ratio of the length of the file and the sample rate to determine the duration in seconds.\n\nsample_rate, signal_data = wavfile.read('../data/jingle_bells.wav')\n\n# Determine the total duration and length of .wav file\nduration = len(signal_data) / sample_rate\ntime = np.arange(0, duration, 1/sample_rate) \n\nprint(f\"Sample Rate: {sample_rate}\")\nprint(f\"Duration = {duration} seconds\")\n\n","type":"content","url":"/wavelet-basics#load-wav-file-for-audio","position":13},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Convert .wav file to pandas dataframe","lvl2":"Load .wav File for Audio"},"type":"lvl3","url":"/wavelet-basics#convert-wav-file-to-pandas-dataframe","position":14},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Convert .wav file to pandas dataframe","lvl2":"Load .wav File for Audio"},"content":"Currently, the signal_data is stored as a numpy array, but to make it easy to plot, we will store the .wav file as a pandas dataframe. This will also associate the specific time (in seconds) with the signal_data amplitude.\n\nsignal_df = pd.DataFrame({'time (seconds)': time, 'amplitude': signal_data})\nsignal_df.head()\n\n","type":"content","url":"/wavelet-basics#convert-wav-file-to-pandas-dataframe","position":15},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Plot a Small Sample of the .wav File","lvl2":"Load .wav File for Audio"},"type":"lvl3","url":"/wavelet-basics#plot-a-small-sample-of-the-wav-file","position":16},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Plot a Small Sample of the .wav File","lvl2":"Load .wav File for Audio"},"content":"With the data stored as a dataframe, it will be simple to plot and view in matplotlib. We can view the first 400 data points (0.04 seconds) as a simple line graph to view the rapidly changing amplitudes.\n\nfig, ax = plt.subplots(figsize=(8, 8))\nfig = plt.plot(signal_df[\"time (seconds)\"], signal_df[\"amplitude\"])\nax.set_xlim(signal_df[\"time (seconds)\"][100], signal_df[\"time (seconds)\"][400])\nplt.title(\"Small Sample of the Audio File\")\nplt.xlabel(\"Time (seconds)\")\nplt.ylabel(\"Amplitude\")\nplt.show()\n\n","type":"content","url":"/wavelet-basics#plot-a-small-sample-of-the-wav-file","position":17},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Fourier Transform - Frequency, but not Time"},"type":"lvl2","url":"/wavelet-basics#fourier-transform-frequency-but-not-time","position":18},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Fourier Transform - Frequency, but not Time"},"content":"\n\n","type":"content","url":"/wavelet-basics#fourier-transform-frequency-but-not-time","position":19},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Advantages (and Disadvantages) of Fourier Transform","lvl2":"Fourier Transform - Frequency, but not Time"},"type":"lvl3","url":"/wavelet-basics#advantages-and-disadvantages-of-fourier-transform","position":20},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Advantages (and Disadvantages) of Fourier Transform","lvl2":"Fourier Transform - Frequency, but not Time"},"content":"The first step of processing new signal data is to develop a basic understanding of the kinds of frequencies that are present. This will help us to answer some important questions:\n\nAre there prevailing patterns?\n\nIs one frequency more dominant?\n\nHow much do the dominant frequencies overcome background noise?\n\nFourier Transform is a common tool that can be used to determine which frequencies are present from raw data. For this “Jingle Bells” musical example, a Fourier Transform will return the frequencies of all the notes that are present.\n\n","type":"content","url":"/wavelet-basics#advantages-and-disadvantages-of-fourier-transform","position":21},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Fast Fourier Transform of Signal Data","lvl2":"Fourier Transform - Frequency, but not Time"},"type":"lvl3","url":"/wavelet-basics#fast-fourier-transform-of-signal-data","position":22},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Fast Fourier Transform of Signal Data","lvl2":"Fourier Transform - Frequency, but not Time"},"content":"To find determine what notes are present, we can first apply Fast Fourier Transform to the .wav file data with the scipy.fftpack.fft() and scipy.fftpack.fftfreq() functions in scipy. These will both return numpy arrays with information about which frequencies are present in the .wav file as well as how frequently they appear.\n\n# Apply FFT to Input Data\nfourier_transform = abs(fft(signal_data))\nfreqs = fftfreq(len(fourier_transform), (1/sample_rate))\n\n","type":"content","url":"/wavelet-basics#fast-fourier-transform-of-signal-data","position":23},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Plot Frequency Prevalence from Fast Fourier Transform","lvl2":"Fourier Transform - Frequency, but not Time"},"type":"lvl3","url":"/wavelet-basics#plot-frequency-prevalence-from-fast-fourier-transform","position":24},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Plot Frequency Prevalence from Fast Fourier Transform","lvl2":"Fourier Transform - Frequency, but not Time"},"content":"To begin, we can plot the Fourier Transform with relation to how frequently a frequency appears.\n\nfig, ax = plt.subplots(figsize=(8, 8))\nplt.plot(freqs, fourier_transform)\nplt.title(\"Signal Frequency Prevalence (FFT)\")\nplt.xlabel('Frequency (Hz)')\nplt.show()\n\n","type":"content","url":"/wavelet-basics#plot-frequency-prevalence-from-fast-fourier-transform","position":25},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Only plot positive Frequencies (hz) in range of notes (200-500)","lvl2":"Fourier Transform - Frequency, but not Time"},"type":"lvl3","url":"/wavelet-basics#only-plot-positive-frequencies-hz-in-range-of-notes-200-500","position":26},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Only plot positive Frequencies (hz) in range of notes (200-500)","lvl2":"Fourier Transform - Frequency, but not Time"},"content":"You might have noticed that the frequencies are mirrored across the 0 Hz, so for simplicity’s sake, we can zoom in and only pay attention to the relevant range of frequencies. For this example, we will pay attention to the positive frequencies between the range frequencies of 200 to 500 Hz where the frequencies for A to G are found.\n\nfig, ax = plt.subplots(figsize=(8, 8))\nplt.plot(freqs, fourier_transform)\nax.set_xlim(left=200, right=500) \nplt.title(\"Signal Frequency Prevalence (FFT)\")\nplt.xlabel('Frequency (Hz)')\nplt.show()\n\n","type":"content","url":"/wavelet-basics#only-plot-positive-frequencies-hz-in-range-of-notes-200-500","position":27},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Plot Fast Fourier Transform","lvl2":"Fourier Transform - Frequency, but not Time"},"type":"lvl3","url":"/wavelet-basics#plot-fast-fourier-transform","position":28},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Plot Fast Fourier Transform","lvl2":"Fourier Transform - Frequency, but not Time"},"content":"We can already start to see the peaks in our data that represent the frequencies in the signal data. There are four apparent peaks, but what notes do they represent?\n\n# Note frequency in hz\na_freq = 440\nb_freq = 494\nc_freq = 261\nd_freq = 293\ne_freq = 330\nf_freq = 350\ng_freq = 392\n\nLet us overlay the possible frequencies (A to G) on the plot to visually see which frequencies are present.\n\nfig, ax = plt.subplots(figsize=(8, 8))\nplt.plot(freqs, fourier_transform)\nax.set_xlim(left=200, right=500) \nplt.axvline(x=a_freq, color=\"lightpink\", label=\"A\",alpha=0.5) # A note: 440 hz\nplt.axvline(x=b_freq, color=\"lightblue\", label=\"B\",alpha=0.5) # B Note: 494 hz\nplt.axvline(x=c_freq, color=\"red\", label=\"C\",alpha=0.5)       # C Note: 261 hz\nplt.axvline(x=d_freq, color=\"green\", label=\"D\",alpha=0.5)     # D Note: 293 hz\nplt.axvline(x=e_freq, color=\"orange\", label=\"E\",alpha=0.5)    # E Note: 330 hz\nplt.axvline(x=f_freq, color=\"grey\", label=\"F\",alpha=0.5)      # F Note: 350 hz\nplt.axvline(x=g_freq, color=\"purple\", label=\"G\",alpha=0.5)    # G Note: 392 hz\nplt.title(\"Signal Frequency Prevalence (FFT)\")\nplt.xlabel('Frequency (Hz)')\nplt.legend()\nplt.show()\n\n","type":"content","url":"/wavelet-basics#plot-fast-fourier-transform","position":29},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Fast Fourier Transform Predicts Four Notes","lvl2":"Fourier Transform - Frequency, but not Time"},"type":"lvl3","url":"/wavelet-basics#fast-fourier-transform-predicts-four-notes","position":30},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Fast Fourier Transform Predicts Four Notes","lvl2":"Fourier Transform - Frequency, but not Time"},"content":"The overlays are working! We can see that the four notes that we predicted from Jingle Bells (C, D, E, and G) are present.\n\nfig, ax = plt.subplots(figsize=(8, 8))\nplt.plot(freqs, fourier_transform)\nax.set_xlim(left=200, right=500) \nplt.axvline(x=c_freq, color=\"red\", label=\"C\",alpha=0.5)    # C Note: 261 hz\nplt.axvline(x=d_freq, color=\"green\", label=\"D\",alpha=0.5)  # D Note: 293 hz\nplt.axvline(x=e_freq, color=\"orange\", label=\"E\",alpha=0.5) # E Note: 330 hz\nplt.axvline(x=g_freq, color=\"purple\", label=\"G\",alpha=0.5) # G Note: 391 hz\nplt.title(\"Signal Frequency Prevalence (FFT)\")\nplt.xlabel('Frequency (Hz)')\nplt.legend()\nplt.show()\n\n","type":"content","url":"/wavelet-basics#fast-fourier-transform-predicts-four-notes","position":31},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Now What?","lvl2":"Fourier Transform - Frequency, but not Time"},"type":"lvl3","url":"/wavelet-basics#now-what","position":32},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Now What?","lvl2":"Fourier Transform - Frequency, but not Time"},"content":"Fourier Transform has been able to illustrate that there are four notes: C, D, E, and G. But what order are the notes in? And how frequently is each note used? Fourier Transform can only give information about the frequency and a ratio of how prevalent a note is—for example, in Jingle Bells, E is significantly more common than any other note.","type":"content","url":"/wavelet-basics#now-what","position":33},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"But to determine both frequency and time, you’ll need a different tool: wavelets!","lvl2":"Fourier Transform - Frequency, but not Time"},"type":"lvl3","url":"/wavelet-basics#but-to-determine-both-frequency-and-time-youll-need-a-different-tool-wavelets","position":34},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"But to determine both frequency and time, you’ll need a different tool: wavelets!","lvl2":"Fourier Transform - Frequency, but not Time"},"content":"\n\n","type":"content","url":"/wavelet-basics#but-to-determine-both-frequency-and-time-youll-need-a-different-tool-wavelets","position":35},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Wavelet Transform - Frequency and Time"},"type":"lvl2","url":"/wavelet-basics#wavelet-transform-frequency-and-time","position":36},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Wavelet Transform - Frequency and Time"},"content":"","type":"content","url":"/wavelet-basics#wavelet-transform-frequency-and-time","position":37},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"What is a Wavelet?","lvl2":"Wavelet Transform - Frequency and Time"},"type":"lvl3","url":"/wavelet-basics#what-is-a-wavelet","position":38},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"What is a Wavelet?","lvl2":"Wavelet Transform - Frequency and Time"},"content":"In its simplest form, a wavelet is a short wave-like oscillation that averages out to zero.\n\n\n\nMany signals and images of interest exhibit piecewise smooth behavior punctuated by transients. Speech signals are characterized by short bursts encoding consonants followed by steady-state oscillations indicative of vowels. Natural images have edges. Financial time series exhibit transient behavior, which characterize rapid upturns and downturns in economic conditions. Unlike the Fourier basis, wavelet bases are adept at sparsely representing piecewise regular signals and images, which include transient behavior.\n\nMathworks: “What is a Wavelet”\n\nFourier transforms are made up of multiple sine waves of different phases and frequencies to best match a signal. However, while Fourier transforms can be used to match frequency, information about when each frequency occurs in the signal is lost. This can be overcome with wavelet analysis. Like Fourier transforms, wavelet analysis works with multiple different wavelets that will be scaled up or down to produce different shaped wavelets that can shifted along the signal. Because the signal is matched by different scaled wavelets at different points along the signal, both the signal’s frequency and the time at which the signal’s frequency occurs can be determined.\n\n","type":"content","url":"/wavelet-basics#what-is-a-wavelet","position":39},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Wavelet Terminology"},"type":"lvl2","url":"/wavelet-basics#wavelet-terminology","position":40},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Wavelet Terminology"},"content":"\n\n","type":"content","url":"/wavelet-basics#wavelet-terminology","position":41},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Wavelet Inputs"},"type":"lvl2","url":"/wavelet-basics#wavelet-inputs","position":42},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Wavelet Inputs"},"content":"Functions for wavelet analysis accept additional parameters as well as the time-series signal data:wavelet(x, wavelet name, dt, s0, dj, jtot)\n\nx: Input time-series data (for example: musical note frequency over time)\n\nwavelet name: name of the mother wavelet\n\ndt: sampling period/rate (time between each y-value)\n\ns0: smallest scale\n\ndj: spacing between each scale\n\njtot: largest scale\n\n","type":"content","url":"/wavelet-basics#wavelet-inputs","position":43},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Time-Series Data","lvl2":"Wavelet Inputs"},"type":"lvl3","url":"/wavelet-basics#time-series-data","position":44},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Time-Series Data","lvl2":"Wavelet Inputs"},"content":"Time-series data is data recorded over known intervals of time. For example, time-series data for weather might track temperature every hour or the time for each recorded amplitude in a musical piece.\n\n","type":"content","url":"/wavelet-basics#time-series-data","position":45},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Mother Wavelet","lvl2":"Wavelet Inputs"},"type":"lvl3","url":"/wavelet-basics#mother-wavelet","position":46},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Mother Wavelet","lvl2":"Wavelet Inputs"},"content":"While a Fourier Transform uses various sine waves to match possible frequencies in a signal, a wavelet is a short wave of various shapes to match possible frequencies and frequency ranges. A wavelet is a small wave over a finite length of time. There are many possible wavelet forms to use, known as Mother Wavelets. Each type of Mother Wavelet is sensitive to a range of possible signals.\n\nThere are a lot of different kind of wavelets to choose from!\n\n","type":"content","url":"/wavelet-basics#mother-wavelet","position":47},{"hierarchy":{"lvl1":"Wavelet Basics","lvl4":"Examples of Possible Mother Wavelets from PyWavelets","lvl3":"Mother Wavelet","lvl2":"Wavelet Inputs"},"type":"lvl4","url":"/wavelet-basics#examples-of-possible-mother-wavelets-from-pywavelets","position":48},{"hierarchy":{"lvl1":"Wavelet Basics","lvl4":"Examples of Possible Mother Wavelets from PyWavelets","lvl3":"Mother Wavelet","lvl2":"Wavelet Inputs"},"content":"Below we can view all the possible mother wavelets present in PyWavelets. There are many different types that are sensitive to different types of frequencies from different types of signals. Most wavelets have a real and imaginary component, which will be used to generate a power and phase spectrum graph from signal data.\n\nBelow are the wavelets available from PyWavelets. As you will notice, most continuous wavelets (CWT) have a real and imaginary component. Typically, only the real component of a wavelet is graphed, but both components include potentially useful information.\n\nDifferent mother wavelets are useful to analyzing data for different features. Morlet is a common wavelet for analyzing the frequencies in data, while Paul is useful to analyze how a signal changes over time and DOG can be used to find discontinuities in data.\n\nwavlist = pywt.wavelist(kind=\"continuous\")\ncols = 3\nrows = (len(wavlist) + cols - 1) // cols\nfig, axs = plt.subplots(rows, cols, figsize=(10, 10),\n                        sharex=True, sharey=True)\nfor ax, wavelet in zip(axs.flatten(), wavlist):\n    # A few wavelet families require parameters in the string name\n    if wavelet in ['cmor', 'shan']:\n        wavelet += '1-1'\n    elif wavelet == 'fbsp':\n        wavelet += '1-1.5-1.0'\n\n    [psi, x] = pywt.ContinuousWavelet(wavelet).wavefun(10)\n    ax.plot(x, np.real(psi), label=\"real\")\n    ax.plot(x, np.imag(psi), label=\"imag\")\n    ax.set_title(wavelet)\n    ax.set_xlim([-5, 5])\n    ax.set_ylim([-0.8, 1])\n\nax.legend(loc=\"upper right\")\nplt.suptitle(\"Available wavelets for CWT in PyWavelets\")\nplt.tight_layout()\nplt.show()\n\n","type":"content","url":"/wavelet-basics#examples-of-possible-mother-wavelets-from-pywavelets","position":49},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Daughter Wavelet","lvl2":"Wavelet Inputs"},"type":"lvl3","url":"/wavelet-basics#daughter-wavelet","position":50},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Daughter Wavelet","lvl2":"Wavelet Inputs"},"content":"A mother wavelet represents the basic wavelet shape that is transformed into varied scaled copies known as daughter wavelets. The daughter wavelets are shifted and scaled along the entire signal to match possible frequencies over a finite period of time.\n\n","type":"content","url":"/wavelet-basics#daughter-wavelet","position":51},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Sampling Period","lvl2":"Wavelet Inputs"},"type":"lvl3","url":"/wavelet-basics#sampling-period","position":52},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Sampling Period","lvl2":"Wavelet Inputs"},"content":"The sampling period of the wavelet matches the sample rate of the audio. This can also be known as the time duration that will be used to determine how wavelets will be matched along the signal data.\n\n","type":"content","url":"/wavelet-basics#sampling-period","position":53},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Scales","lvl2":"Wavelet Inputs"},"type":"lvl3","url":"/wavelet-basics#scales","position":54},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Scales","lvl2":"Wavelet Inputs"},"content":"Wavelets matche various frequencies by stretching and shrinking the mother wavelet based on a range of possible scales.\n\nStretched Wavelet: A large wavelet will capture large features, low frequencies, slow frequencies\n\nShrunk Wavelet: A small wavelet will capture small features and high frequencies, as well as sudden changing frequencies\n\n","type":"content","url":"/wavelet-basics#scales","position":55},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Continuous Wavelet Transform (CWT) vs. Discrete Wavelet Transform (DWT)","lvl2":"Wavelet Inputs"},"type":"lvl3","url":"/wavelet-basics#continuous-wavelet-transform-cwt-vs-discrete-wavelet-transform-dwt","position":56},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"Continuous Wavelet Transform (CWT) vs. Discrete Wavelet Transform (DWT)","lvl2":"Wavelet Inputs"},"content":"There are two classes of wavelets: continuous and discrete wavelet transforms.\n\nContinuous wavelet transform (CWT) are useful when working with time-frequency data and working with changing frequencies.\n\n\n\nDiscrete wavelets transforms (DWT) are useful when working with images for tasks like denoising or compressing an image while preserving important details.\n\n\n\n\n\n","type":"content","url":"/wavelet-basics#continuous-wavelet-transform-cwt-vs-discrete-wavelet-transform-dwt","position":57},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Summary"},"type":"lvl2","url":"/wavelet-basics#summary","position":58},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Summary"},"content":"Wavelets are a powerful tool for processing time-series data. While Fourier Transforms are a common method of signal analysis, they only return the information about the frequency of the signal and not when the frequencies occur or their duration. Wavelets are an answer to this limitation in Fourier Transform. However, due to Heisenberg’s Uncertainty Principle, it is impossible to exactly know both the exact frequency and the exact time that the frequency occurs in a signal. Fourier Transform can return highly precise information about the frequencies in a signal and the wavelet transform can return both the frequency and time, but by reducing the precision of the frequency.\n\nWe will see how this precision varies, but as a result it can be useful to not entirely abandon Fourier Transform. Wavelets and Fourier Transform can both be used to analyze data, by utilizing their strengths and offsetting each others weaknesses.","type":"content","url":"/wavelet-basics#summary","position":59},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/wavelet-basics#whats-next","position":60},{"hierarchy":{"lvl1":"Wavelet Basics","lvl3":"What’s next?","lvl2":"Summary"},"content":"Up next: apply wavelet transforms to determine the order of frequency signals for music and weather analysis!\n\n","type":"content","url":"/wavelet-basics#whats-next","position":61},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Resources and references"},"type":"lvl2","url":"/wavelet-basics#resources-and-references","position":62},{"hierarchy":{"lvl1":"Wavelet Basics","lvl2":"Resources and references"},"content":"MathWorks Wavelet Transforms\n\nMathWorks: “What is a Wavelet”","type":"content","url":"/wavelet-basics#resources-and-references","position":63}]}